import numpy as np
import heapq
from collections import defaultdict, Counter
import math
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple

class HuffmanCoder:
    """
    Huffman Coding implementation for lossless compression
    """
    
    class Node:
        """Node class for Huffman tree"""
        def __init__(self, symbol: str, freq: float):
            self.symbol = symbol
            self.freq = freq
            self.left = None
            self.right = None
        
        def __lt__(self, other):
            return self.freq < other.freq
        
        def __eq__(self, other):
            return self.freq == other.freq

    def __init__(self):
        self.codes = {}
        self.reverse_codes = {}
    
    def build_tree(self, freq_dict: Dict[str, float]) -> Node:
        """Build Huffman tree from frequency dictionary"""
        priority_queue = []
        
        for symbol, freq in freq_dict.items():
            node = self.Node(symbol, freq)
            heapq.heappush(priority_queue, node)
        
        while len(priority_queue) > 1:
            left = heapq.heappop(priority_queue)
            right = heapq.heappop(priority_queue)
            
            merged = self.Node(None, left.freq + right.freq)
            merged.left = left
            merged.right = right
            
            heapq.heappush(priority_queue, merged)
        
        return priority_queue[0] if priority_queue else None

    def build_codes(self, node: Node, current_code: str = ""):
        """Build codes by traversing Huffman tree"""
        if node is None:
            return
        
        if node.symbol is not None:
            self.codes[node.symbol] = current_code
            self.reverse_codes[current_code] = node.symbol
            return
        
        self.build_codes(node.left, current_code + "0")
        self.build_codes(node.right, current_code + "1")

    def encode(self, data: List[str]) -> Tuple[str, Dict]:
        """Encode data using Huffman codes"""
        if not data:
            return "", {}
        
        # Calculate frequencies
        freq_dict = Counter(data)
        total = len(data)
        
        # Normalize frequencies to probabilities
        prob_dict = {sym: count/total for sym, count in freq_dict.items()}
        
        # Build Huffman tree and codes
        root = self.build_tree(freq_dict)
        self.build_codes(root)
        
        # Encode data
        encoded_bits = "".join(self.codes[symbol] for symbol in data)
        
        # Calculate compression metrics
        original_size = len(data)
        compressed_size = len(encoded_bits)
        
        # Calculate average code length
        avg_code_length = sum(prob_dict[sym] * len(self.codes[sym]) 
                            for sym in prob_dict)
        
        # Calculate entropy
        entropy = -sum(prob * math.log2(prob) for prob in prob_dict.values() 
                      if prob > 0)
        
        compression_info = {
            'original_size': original_size,
            'compressed_size': compressed_size,
            'compression_ratio': original_size / compressed_size if compressed_size > 0 else 1,
            'average_code_length': avg_code_length,
            'entropy': entropy,
            'efficiency': (entropy / avg_code_length) * 100 if avg_code_length > 0 else 0
        }
        
        return encoded_bits, compression_info

    def decode(self, encoded_bits: str) -> List[str]:
        """Decode Huffman encoded bits"""
        current_code = ""
        decoded_data = []
        
        for bit in encoded_bits:
            current_code += bit
            if current_code in self.reverse_codes:
                decoded_data.append(self.reverse_codes[current_code])
                current_code = ""
        
        return decoded_data

def generate_bernoulli_sequence(p: float, length: int = 10000) -> List[int]:
    """Generate Bernoulli sequence with parameter p"""
    return np.random.choice([0, 1], size=length, p=[1-p, p]).tolist()

def generate_er_graph(n: int, p: float) -> np.ndarray:
    """Generate Erdos-Renyi graph G(n, p)"""
    adj_matrix = np.zeros((n, n), dtype=int)
    
    for i in range(n):
        for j in range(i+1, n):
            if np.random.random() < p:
                adj_matrix[i, j] = 1
                adj_matrix[j, i] = 1
    
    return adj_matrix

def flatten_adjacency_matrix(adj_matrix: np.ndarray) -> List[str]:
    """Extract upper triangular elements as sequence"""
    n = adj_matrix.shape[0]
    flat_sequence = []
    
    for i in range(n):
        for j in range(i+1, n):
            flat_sequence.append(str(adj_matrix[i, j]))
    
    return flat_sequence

def block_sequence(sequence: List[int], block_size: int) -> List[str]:
    """Convert sequence to blocks of specified size"""
    blocked = []
    
    for i in range(0, len(sequence), block_size):
        if i + block_size <= len(sequence):
            block = sequence[i:i + block_size]
            block_str = ''.join(str(bit) for bit in block)
            blocked.append(block_str)
    
    return blocked

def calculate_theoretical_entropy(p: float) -> float:
    """Calculate theoretical entropy of Bernoulli source"""
    if p == 0 or p == 1:
        return 0.0
    return -p * math.log2(p) - (1-p) * math.log2(1-p)

def run_bernoulli_experiments():
    """Run compression experiments on Bernoulli sequences"""
    print("=== BERNOULLI SEQUENCE COMPRESSION EXPERIMENTS ===\n")
    
    p_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
    block_size = 4
    sequence_length = 10000
    
    results = []
    
    for p in p_values:
        # Generate sequence
        sequence = generate_bernoulli_sequence(p, sequence_length)
        
        # Apply blocking
        blocked_sequence = block_sequence(sequence, block_size)
        
        # Compress
        coder = HuffmanCoder()
        encoded_bits, compression_info = coder.encode(blocked_sequence)
        
        # Calculate theoretical metrics
        theoretical_entropy = calculate_theoretical_entropy(p)
        
        # Store results
        result = {
            'probability': p,
            'theoretical_entropy': theoretical_entropy,
            'empirical_entropy': compression_info['entropy'],
            'average_code_length': compression_info['average_code_length'],
            'compression_ratio': compression_info['compression_ratio'],
            'efficiency': compression_info['efficiency'],
            'original_size': compression_info['original_size'] * block_size,
            'compressed_size': compression_info['compressed_size']
        }
        results.append(result)
        
        print(f"p = {p:.1f}: "
              f"Theoretical H = {theoretical_entropy:.3f}, "
              f"Avg Code Length = {compression_info['average_code_length']:.3f}, "
              f"CR = {compression_info['compression_ratio']:.3f}, "
              f"Efficiency = {compression_info['efficiency']:.1f}%")
    
    return results

def run_blocking_analysis():
    """Analyze effect of block size on compression"""
    print("\n=== BLOCKING ANALYSIS ===\n")
    
    p = 0.2
    sequence_length = 10000
    block_sizes = [1, 2, 4, 8]
    
    sequence = generate_bernoulli_sequence(p, sequence_length)
    results = []
    
    for block_size in block_sizes:
        if block_size == 1:
            blocked_sequence = [str(bit) for bit in sequence]
        else:
            blocked_sequence = block_sequence(sequence, block_size)
        
        coder = HuffmanCoder()
        encoded_bits, compression_info = coder.encode(blocked_sequence)
        
        theoretical_entropy = calculate_theoretical_entropy(p)
        
        result = {
            'block_size': block_size,
            'alphabet_size': 2 ** block_size,
            'compression_ratio': compression_info['compression_ratio'],
            'average_code_length': compression_info['average_code_length'],
            'efficiency': compression_info['efficiency'],
            'theoretical_entropy': theoretical_entropy
        }
        results.append(result)
        
        print(f"Block Size: {block_size}, "
              f"Alphabet Size: {2 ** block_size}, "
              f"CR: {compression_info['compression_ratio']:.3f}, "
              f"Avg Length: {compression_info['average_code_length']:.3f}, "
              f"Efficiency: {compression_info['efficiency']:.1f}%")
    
    return results

def run_graph_compression_experiments():
    """Run compression experiments on ER graphs"""
    print("\n=== ER GRAPH COMPRESSION EXPERIMENTS ===\n")
    
    n = 100  # Number of vertices
    p_values = [0.1, 0.3, 0.5, 0.7, 0.9]
    block_size = 2
    
    results = []
    
    for p in p_values:
        # Generate graph
        adj_matrix = generate_er_graph(n, p)
        
        # Flatten adjacency matrix
        flat_sequence = flatten_adjacency_matrix(adj_matrix)
        
        # Apply blocking
        int_sequence = [int(bit) for bit in flat_sequence]
        blocked_sequence = block_sequence(int_sequence, block_size)
        
        # Compress
        coder = HuffmanCoder()
        encoded_bits, compression_info = coder.encode(blocked_sequence)
        
        # Calculate graph statistics
        original_size = len(flat_sequence)
        edge_count = sum(int(bit) for bit in flat_sequence)
        density = edge_count / original_size
        
        result = {
            'probability': p,
            'original_size': original_size,
            'compressed_size': compression_info['compressed_size'],
            'compression_ratio': original_size / compression_info['compressed_size'],
            'edge_count': edge_count,
            'density': density,
            'theoretical_entropy': calculate_theoretical_entropy(p)
        }
        results.append(result)
        
        print(f"p = {p:.1f}: "
              f"Original = {original_size} bits, "
              f"Compressed = {compression_info['compressed_size']} bits, "
              f"CR = {original_size / compression_info['compressed_size']:.3f}, "
              f"Density = {density:.3f}")
    
    return results

def plot_results(bernoulli_results, blocking_results, graph_results):
    """Create visualization of results"""
    plt.style.use('seaborn-v0_8')
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # Plot 1: Bernoulli compression results
    probabilities = [r['probability'] for r in bernoulli_results]
    compression_ratios = [r['compression_ratio'] for r in bernoulli_results]
    entropies = [r['theoretical_entropy'] for r in bernoulli_results]
    
    ax1.plot(probabilities, compression_ratios, 'b-o', linewidth=2, markersize=8, label='Compression Ratio')
    ax1.set_xlabel('Probability p')
    ax1.set_ylabel('Compression Ratio')
    ax1.set_title('Bernoulli Sequence Compression Ratio vs Probability')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    ax1_twin = ax1.twinx()
    ax1_twin.plot(probabilities, entropies, 'r--s', linewidth=2, markersize=6, label='Entropy')
    ax1_twin.set_ylabel('Entropy (bits)')
    ax1_twin.legend(loc='upper right')
    
    # Plot 2: Blocking analysis
    block_sizes = [r['block_size'] for r in blocking_results]
    blocking_ratios = [r['compression_ratio'] for r in blocking_results]
    efficiencies = [r['efficiency'] for r in blocking_results]
    
    ax2.plot(block_sizes, blocking_ratios, 'g-o', linewidth=2, markersize=8, label='Compression Ratio')
    ax2.set_xlabel('Block Size')
    ax2.set_ylabel('Compression Ratio')
    ax2.set_title('Effect of Block Size on Compression (p=0.2)')
    ax2.grid(True, alpha=0.3)
    ax2.legend()
    
    ax2_twin = ax2.twinx()
    ax2_twin.plot(block_sizes, efficiencies, 'm--^', linewidth=2, markersize=6, label='Efficiency (%)')
    ax2_twin.set_ylabel('Efficiency (%)')
    ax2_twin.legend(loc='lower right')
    
    # Plot 3: Graph compression
    graph_probs = [r['probability'] for r in graph_results]
    graph_ratios = [r['compression_ratio'] for r in graph_results]
    
    ax3.plot(graph_probs, graph_ratios, 'purple-o', linewidth=2, markersize=8)
    ax3.set_xlabel('Edge Probability p')
    ax3.set_ylabel('Compression Ratio')
    ax3.set_title('ER Graph Compression Ratio vs Edge Probability')
    ax3.grid(True, alpha=0.3)
    
    # Plot 4: Code length vs entropy
    code_lengths = [r['average_code_length'] for r in bernoulli_results]
    
    ax4.plot(entropies, code_lengths, 'orange-o', linewidth=2, markersize=8, label='Average Code Length')
    ax4.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Theoretical Limit')
    ax4.set_xlabel('Entropy (bits)')
    ax4.set_ylabel('Average Code Length (bits)')
    ax4.set_title('Code Length vs Entropy')
    ax4.grid(True, alpha=0.3)
    ax4.legend()
    
    plt.tight_layout()
    plt.savefig('compression_results.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """Main execution function"""
    print("ECE 2414 Lab 2: Lossless Compression of Bernoulli Sequences and ER Graphs")
    print("=" * 80)
    
    # Run experiments
    bernoulli_results = run_bernoulli_experiments()
    blocking_results = run_blocking_analysis()
    graph_results = run_graph_compression_experiments()
    
    # Create visualizations
    plot_results(bernoulli_results, blocking_results, graph_results)
    
    # Print summary
    print("\n" + "=" * 80)
    print("EXPERIMENT SUMMARY")
    print("=" * 80)
    
    print(f"\nBernoulli Sequences:")
    print(f"- Maximum compression ratio: {max(r['compression_ratio'] for r in bernoulli_results):.3f} (p=0.1, 0.9)")
    print(f"- Minimum compression ratio: {min(r['compression_ratio'] for r in bernoulli_results):.3f} (p=0.5)")
    print(f"- Best efficiency: {max(r['efficiency'] for r in bernoulli_results):.1f}%")
    
    print(f"\nBlocking Analysis:")
    print(f"- Best block size: {max(blocking_results, key=lambda x: x['compression_ratio'])['block_size']}")
    print(f"- Maximum compression with blocking: {max(r['compression_ratio'] for r in blocking_results):.3f}")
    
    print(f"\nER Graph Compression:")
    print(f"- Maximum graph compression: {max(r['compression_ratio'] for r in graph_results):.3f}")
    print(f"- All experiments completed successfully!")
    
    # Save results to files
    import json
    with open('bernoulli_results.json', 'w') as f:
        json.dump(bernoulli_results, f, indent=2)
    with open('graph_results.json', 'w') as f:
        json.dump(graph_results, f, indent=2)

if __name__ == "__main__":
    main()
